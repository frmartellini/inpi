{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download de pareceres de patentes da Inova Unicamp\n",
    "\n",
    "*por Francisco Martellini - setembro 2020*\n",
    "\n",
    "Este notebook foi construído para uso interno da Agência de Inovação da Unicamp, e possui algumas especificidades para a nomeação dos arquivos gerados e execução no ambiente do Google Colab.\n",
    "\n",
    "Caso deseje implementá-lo em sua organização, procure pela versão geral (**pyINPI - Patentes.ipynb**) no meu repositório do GitHub, que possui o mesmo código sem as especificidades feitas para a Inova Unicamp.\n",
    "\n",
    "Você pode encontrar meu repositório com o arquivo em **<https://github.com/frmartellini/inpi>**.\n",
    "\n",
    "## Instruções\n",
    "\n",
    "### i) Para fazer a busca na RPI e o download dos pareceres\n",
    "\n",
    "Execute todas as partes deste arquivo, uma de cada vez, no Google Colab. Clique no ícone da pasta na barra lateral e faça o download do pacote zip com todos os arquivos baixados e do arquivo xlsx com o relatório de pareceres da semana.\n",
    "\n",
    "**Importante!** Os arquivos dos pareceres para download estão disponíveis somente depois das 15:30h da terça-feira da semana (ou da quarta-feira, quando terça for feriado). Executar antes deste horário irá gerar erro na execução.\n",
    "\n",
    "### ii) Somente fazer a busca na RPI da semana e gerar um relatório com as informações\n",
    "\n",
    "Execute no Google Colab, exatamente nesta ordem: **Parte 1**, **Parte 2**, **Parte 3** e **Parte 4**. Clique no ícone da pasta na barra lateral e faça o download do arquivo xlsx. **Não execute as outras partes do programa neste caso!**.\n",
    "\n",
    "**Importante!** As informações da RPI são disponibilizadas na parte da manhã da terça-feira da semana (ou da quarta-feira, quando terça for feriado), a partir das 08:00h. Neste caso, o programa pode ser usado sem gerar erro na execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "109ljONzHOP_"
   },
   "outputs": [],
   "source": [
    "#@title PARTE 1: CARREGAR BIBLIOTECAS E FUNÇÕES\n",
    "\n",
    "#### BIBLIOTECAS NECESSÁRIAS\n",
    "\n",
    "import requests # método request\n",
    "import os # comandos de arquivo/diretório\n",
    "import pandas as pd # pandas dataframe\n",
    "import numpy as np # numpy\n",
    "import sys\n",
    "import shutil # apagar uma ársvore de pastas\n",
    "import zipfile\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "####  FUNÇÕES E CLASSES\n",
    "\n",
    "def excel_report(xls_df,xls_name,sheet_name):\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    # also set the default datetime and date formats.\n",
    "    writer = pd.ExcelWriter(xls_name + \".xlsx\", engine='xlsxwriter', date_format='dd/mm/yyyy')\n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    xls_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    # Get the xlsxwriter workbook and worksheet objects in order to set the column\n",
    "    # widths, to make the dates clearer.\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    \n",
    "    #Iterate through each column and set the width == the max length in that column. A padding length of 2 is also added.\n",
    "    for i, col in enumerate(xls_df.columns):\n",
    "        column_len = xls_df[col].astype(str).str.len().max() # find length of column i\n",
    "        column_len = max(column_len, len(col)) + 2 # Setting the length if the column header is larger than the max column value length\n",
    "        worksheet.set_column(i, i, column_len) # set the column length\n",
    "    \n",
    "    # Close the Pandas Excel writer and output the Excel file\n",
    "    writer.save()\n",
    "    print(\"Relatório concluído.\")\n",
    "\n",
    "def inova_sici(df_sici):\n",
    "    df_sici.columns = map(str.lower, df_sici.columns) # coloca o nome das colunas em minúsculo\n",
    "    df_sici.drop(df_sici.columns.difference(['tecnologia','pi','revista','despacho']), axis=1, inplace=True)\n",
    "    df_sici.columns = ['tecnologia','pi_sici','rpi','cod_despacho']\n",
    "\n",
    "    # Cria a coluna busca no dataframe\n",
    "    df_sici['cod_busca'] = df_sici['pi_sici'] # Cria a coluna busca com base na PI\n",
    "    df_sici['cod_busca'] = df_sici['cod_busca'].str[:-2] # remove o digito identificador\n",
    "    df_sici['cod_busca'] = df_sici['cod_busca'].str.replace(' ', '') # remove os espaços em branco\n",
    "    df_sici['cod_busca'] = df_sici['cod_busca'].str.replace('BR', '') # remove o código BR\n",
    "    \n",
    "    #Se a tecnologia for antiga (o campo do nome está vazio), substitui tecnologia por pi\n",
    "    df_sici.tecnologia.replace(\"\", df_sici['pi_sici'], regex=True, inplace=True)\n",
    "    df_sici.drop(['pi_sici'], axis=1, inplace=True) # remove a coluna pi sici\n",
    "    \n",
    "    df_sici['rpi'] = df_sici['rpi'].astype('int')\n",
    "    df_sici['cod_busca'] = df_sici['cod_busca'].astype('str')\n",
    "    df_sici['cod_despacho'] = df_sici['cod_despacho'].astype('str')    \n",
    "    print(\"Dataframe do SICI construído.\")\n",
    "    \n",
    "# Classes para acessar as informações da aplicativo web do INPI\n",
    "class api_inpi:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "    \n",
    "    # Verifica o código de status do arquivo no servidor\n",
    "    def url_status(self):\n",
    "        r = requests.head(self.url)\n",
    "        return r.status_code\n",
    "    \n",
    "    # Faz o download do arquivo no pacote zip com a extensão escolhida para a memória\n",
    "    def xml_extract(self):\n",
    "        if self.url_status() == 200: # Se o código for 200, procede com download\n",
    "            #r = requests.get(self.url) # Primeiro faz a requisição do arquivo para o servidor        \n",
    "            #f_zip = zipfile.ZipFile(io.BytesIO(r.content)) # para simular um objeto do tipo bytes para o arquivo zip\n",
    "            #f_names = f_zip.namelist() # depois lista todos os arquivos do pacote compactado\n",
    "            #f_name = [i for i in f_names if ext in i][0] # para localizar o arquivo com a extensão desejada\n",
    "            #return f_zip.read(f_name) # retornando o conteúdo do arquivo para a memória\n",
    "            r = requests.get(url, stream=True)\n",
    "            z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "            f_names = z.namelist() # depois lista todos os arquivos do pacote compactado\n",
    "            for fileName in f_names:\n",
    "                if fileName.endswith('.xml'): # Check filename endswith xml\n",
    "                    z.extract(fileName) # Extract a single file from zip\n",
    "            return fileName # return the name of the file\n",
    "        if self.url_status() == 302: # Mas se o código for 302, o arquivo ainda não existe\n",
    "            print(\"404: O arquivo solicitado não existe.\") # então imprime uma mensagem de erro\n",
    "            \n",
    "    # Busca os pareceres de patentes para uma instituição por titular ou cotitular\n",
    "    def busca_titular(self,revista,org,df):\n",
    "        rpi = revista # número da RPI a ser verificada\n",
    "        #ext = \".xml\" # extensão do arquivo para ser extraído do pacote zip\n",
    "        f_xml = self.xml_extract() # verifica o status do arquivo no servidor e realiza o download para a memória\n",
    "        #xml_data = xml_extract().content\n",
    "        infile = open(f_xml,\"r\")\n",
    "        xml_data = infile.read()\n",
    "        xml_data = re.sub(' +',' ',xml_data) # substitui espaçamentos múltiplos por espaçamentos únicos\n",
    "        soup = BeautifulSoup(xml_data, \"xml\") # passing the stored data inside the beautifulsoup parser, storing the returned object\n",
    "        \n",
    "        org_soup = soup.find_all('nome-completo', text=lambda x: x is not None and org in x.casefold()) # Busca quantas vezes o nome da(s) organização(ões) apareceu na RPI\n",
    "        data_revista = soup.find('revista').attrs.get('dataPublicacao') # Extrai a data de publicação\n",
    "        \n",
    "        despacho_len = len(org_soup) # quantidade total de registros com os critérios solicitados\n",
    "        for i in range(despacho_len): # percorre o arquivo da revista em busca dos despachos com os critérios solicitados\n",
    "            despacho_soup = org_soup[i].find_parent('despacho')\n",
    "            \n",
    "            # Procura o número da proteção em toda a revista para verificar repetições\n",
    "            registro_soup = soup.find_all(\"numero\", text=lambda x: despacho_soup.find('numero').text in x) # Busca quantas vezes o nome da(s) organização(ões) apareceu na RPI\n",
    "            registro_len = len(registro_soup)\n",
    "            gestao = \"\"\n",
    "            flag = 1\n",
    "            for j in range(registro_len): # extrai as informações individualmente de casa número de proteção repetido\n",
    "                registros = registro_soup[j].find_parent('despacho')\n",
    "        \n",
    "                # Procura o código de despacho\n",
    "                cod_despacho = registros.find('codigo')\n",
    "                if cod_despacho != None:\n",
    "                    cod_despacho = cod_despacho.text\n",
    "                    \n",
    "                # Procura o título da invenção\n",
    "                titulo = registros.find(\"titulo\", inid=\"54\")\n",
    "                if titulo != None:\n",
    "                    titulo = titulo.text\n",
    "        \n",
    "                # Procura o número da proteção\n",
    "                registro = registros.find('numero')\n",
    "                if registro != None:\n",
    "                    registro = registro.text\n",
    "                    \n",
    "                # Monta o codigo de busca para o servidor\n",
    "                cod_busca = registro[:-2].replace(' ', '').replace('BR', '')\n",
    "                                \n",
    "                # Procura o kind code\n",
    "                kindcode = registros.find('numero').attrs.get('kindcode')\n",
    "    \n",
    "                # Procura a data de depósito\n",
    "                data_deposito = registros.find('data-deposito')\n",
    "                if data_deposito != None:\n",
    "                    data_deposito = data_deposito.text\n",
    "\n",
    "                # Procura os dados de classificação internacional\n",
    "                ci_len = len(registros.find_all(\"classificacao-internacional\"))\n",
    "                ci = \"\"\n",
    "                if ci_len > 0:\n",
    "                    for i in range(ci_len):\n",
    "                        ci_ano = registros.find_all(\"classificacao-internacional\")[i].text + \" (\" + registros.find_all(\"classificacao-internacional\")[i].attrs.get('ano') + \")\"\n",
    "                        ci = ci + ci_ano + \" | \"\n",
    "                ci = ci[:-3]\n",
    "            \n",
    "                # Verifica se é gestão interna\n",
    "                titular_1 = registros.find(\"titular\", sequencia=\"1\")\n",
    "                if titular_1 != None and flag == 1:\n",
    "                    nome_completo = titular_1.find(\"nome-completo\").text\n",
    "                    if org.lower() not in nome_completo.lower(): # Caso o primeiro titular não seja a organização procurada, a gestão é externa\n",
    "                        gestao = \"Não\"\n",
    "                    if org.lower() in nome_completo.lower(): # Caso o primeiro titular não seja a organização procurada, a gestão é externa\n",
    "                        gestao = \"Sim\"\n",
    "                flag = 2\n",
    "\n",
    "                # Procura a lista de titulares\n",
    "                titular_len = len(registros.find_all(\"titular\"))\n",
    "                titulares = \"\"\n",
    "                if titular_len > 0:\n",
    "                    for i in range(titular_len):\n",
    "                        titular = registros.find_all(\"titular\")[i].find(\"nome-completo\").text\n",
    "                        titulares = titulares + titular + \" | \"\n",
    "                titulares = titulares[:-3]\n",
    "    \n",
    "                # Procura a lista de inventores\n",
    "                inventor_len = len(registros.find_all(\"inventor\"))\n",
    "                inventores = \"\"\n",
    "                if inventor_len > 0:\n",
    "                    for i in range(inventor_len):\n",
    "                        inventor = registros.find_all(\"inventor\")[i].find(\"nome-completo\").text\n",
    "                        inventores = inventores + inventor + \" | \"\n",
    "                inventores = inventores[:-3]\n",
    "                \n",
    "                df.loc[len(df)] = [rpi, data_revista,registro, kindcode, cod_despacho,titulo,gestao, titulares, inventores, data_deposito, ci,cod_busca]\n",
    "        \n",
    "        df['rpi'] = df['rpi'].astype('int')\n",
    "        df['cod_busca'] = df['cod_busca'].astype('str')\n",
    "        df['cod_despacho'] = df['cod_despacho'].astype('str')\n",
    "        os.remove(f_xml)\n",
    "\n",
    "def download_parecer(df):\n",
    "    df.dropna(subset = ['registro'], inplace=True) # remove as linhas onde pi é NaN\n",
    "    df.dropna(subset = ['inpi_name'], inplace=True) # remove as linhas onde inpi_name é NaN\n",
    "\n",
    "    df['download'] = True\n",
    "    \n",
    "    # Casos em que uma proteção tem dois despachos na mesma revista\n",
    "    # manter somente o despacho que tem dois documentos\n",
    "    patentes_df.loc[patentes_df.cod_despacho == \"15.11\", \"download\"] = False # duplo com 6.22\n",
    "    patentes_df.loc[patentes_df.cod_despacho == \"8.7\", \"download\"] = False # duplo com 7.5\n",
    "    \n",
    "    # Carta patente não se encontra no mesmo servidor que os pareceres\n",
    "    # e devem ser baixados diretamente no siste do INPI\n",
    "    patentes_df.loc[patentes_df.cod_despacho == \"16.1\", \"download\"] = False\n",
    "    \n",
    "    df.loc[df['download'] == False,'download'] = np.nan # Troca o valor False de download por NaN\n",
    "    df.dropna(subset = ['download'], inplace=True) # remove as linhas onde download é NaN   \n",
    "    df.drop(['download'], axis=1, inplace=True) # remove a coluna download\n",
    "    \n",
    "    # Adicionando flags de contagem procurando arquivos duplicados\n",
    "    df['dupl'] = df['registro'].duplicated(keep=False)\n",
    "    df['flag'] = df.groupby('registro').cumcount()\n",
    "    df.loc[df['dupl'] == False, 'flag'] = \"\" # flag é vazio se não houver duplicidade\n",
    "\n",
    "    dict_letters = {'' : '', 0 : '_A',1 : '_B', 2 : '_C', 3 : '_D', 4 : '_E',\n",
    "                    5 : '_F', 6 : '_G', 7 : '_H', 8 : '_I', 9 : '_J'}\n",
    "    df['flag']= df['flag'].map(dict_letters) \n",
    "    df.drop(['dupl'], axis=1, inplace=True) # remove a coluna dupl\n",
    "    \n",
    "    df['f_name'] = df['f_name'] + df['flag'] + '.pdf'\n",
    "    df.drop(['flag'], axis=1, inplace=True) # remove a coluna flag\n",
    "    \n",
    "    i = 1 # contador de posição de linha do dataframe\n",
    "    for folder_name,inpi_name,f_name,rpi in zip(df['folder_name'],df['inpi_name'],df['f_name'],df['rpi']):\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "        url_cam = \"http://parecer.inpi.gov.br/download.php?cam=arquivos/RPI/\" + str(rpi) + '/' + inpi_name\n",
    "        f_request = requests.get(url_cam, verify = False)\n",
    "        path = folder_name + \"/\" + f_name\n",
    "        f = open(path, 'wb').write(f_request.content) # faz o download do arquivo\n",
    "        i+=1\n",
    "\n",
    "    print(\"Download dos arquivos concluídos!\")\n",
    "    \n",
    "print(\"Bibliotecas carregadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "h98q8LympvQA"
   },
   "outputs": [],
   "source": [
    "#@title PARTE 2: DIGITE A RPI PARA A BUSCA\n",
    "\n",
    "rpi_i =  input(\"Digite o número da RPI:\\n\")\n",
    "rpi_i = int(rpi_i)\n",
    "rpi_f =  rpi_i # somente implementar a busca em uma série de RPIs caso necessário\n",
    "rpi_f = int(rpi_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "f1aDQuL4HORC"
   },
   "outputs": [],
   "source": [
    "#@title PARTE 3: CARREGAR ARQUIVO DO SICI\n",
    "\n",
    "# Para uso no Google Colab\n",
    "\n",
    "from google.colab import files # para uso no google colab\n",
    "!pip install -q XlsxWriter # para uso no google colab\n",
    "\n",
    "print('\\033[1m' + \"\\nCarregue o arquivo do SICI com a revista da semana\\n\" + '\\033[0m')\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    arquivo=fn\n",
    "    f_sici = arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "U4UdZtgJ0cV3"
   },
   "outputs": [],
   "source": [
    "#@title PARTE 4: FAZER A BUSCA NA SEÇÃO DE PATENTES DA RPI\n",
    "\n",
    "# Cria o dataframe para armazenar as informações da RPI de patentes\n",
    "column_names = ['rpi','data de publicação','registro','kind code','cod_despacho','título','gestão','titulares','inventores','data de deposito','classificação internacional','cod_busca'] # cria as colunas do dataframe\n",
    "patentes_df = pd.DataFrame(columns=column_names) # cria o dataframe\n",
    "\n",
    "rpi = rpi_i\n",
    "for i in range(rpi_f-rpi_i+1):\n",
    "    url = \"http://revistas.inpi.gov.br/txt/P\" + str(rpi) + \".zip\"\n",
    "    \n",
    "    # Para fazer a busca de patentes\n",
    "    # usar: api_inpi(url).busca_titular(rpi,\"nome da instituição\",nome do dataframe)\n",
    "    #\n",
    "    #   url = url da seção de patentes da rpi para a revista escolhida (str)\n",
    "    #   rpi = numero da revista (int)\n",
    "    #   nome = nome completo da instituição em lower case (str)\n",
    "    #   dataframe = nome do dataframe para armazenamento\n",
    "    \n",
    "    api_inpi(url).busca_titular(rpi,\"universidade estadual de campinas\",patentes_df)\n",
    "    rpi+=1\n",
    "\n",
    "# Mescla com o arquivo do SICI\n",
    "df_sici = pd.read_html(f_sici, encoding='utf-8', header=0)[0].iloc[:-1] # Converte o arquivo html em um dataframe e remove a última linha\n",
    "inova_sici(df_sici)\n",
    "\n",
    "patentes_df = pd.merge(patentes_df, df_sici, left_on=['rpi','cod_busca','cod_despacho'],right_on=['rpi','cod_busca','cod_despacho'],how='left')\n",
    "patentes_df = patentes_df[['rpi','data de publicação','tecnologia','registro','kind code','cod_despacho','título','gestão','titulares','inventores','data de deposito','classificação internacional','cod_busca']]\n",
    "del df_sici\n",
    "\n",
    "patentes_df['tecnologia'] = np.where(patentes_df['tecnologia'] == \"_\", patentes_df['registro'], patentes_df['tecnologia']) # padrão de nome das tecnologias antigas\n",
    "\n",
    "# Gera o relatório de pareceres\n",
    "\n",
    "if rpi_f > rpi_i:\n",
    "    f_name = \"rpi_patentes_\" + str(rpi_i) + \"-\" + str(rpi_f)\n",
    "    s_name = str(rpi_i) + \" - \" + str(rpi_f)\n",
    "if rpi_f <= rpi_i:\n",
    "    f_name = \"rpi_patentes_\" + str(rpi_i)\n",
    "    s_name = str(rpi_i)\n",
    "    \n",
    "excel_report(patentes_df.iloc[:,:-1],f_name,s_name)\n",
    "\n",
    "# Define as colunas de download no padrão do SICI-Inova\n",
    "patentes_df[['nr_tech', 'nome_tech']] = patentes_df['tecnologia'].str.split('_', 1, expand=True) #split only in the first pattern finded\n",
    "patentes_df['nr_tech'] = patentes_df['nr_tech'].str.zfill(3) # se o número da tecnologia for menor que 100 adiciona zeros na frente\n",
    "patentes_df['nr_tech'] = patentes_df['nr_tech'] + \"_\" # adiciona underline após o número\n",
    "\n",
    "# Caso das tecnologias antigas - NaN and None values\n",
    "patentes_df = patentes_df.fillna(value=np.nan) # replace all None values with NaN\n",
    "patentes_df = patentes_df.fillna('') # replace all NaN with empty spaces\n",
    "\n",
    "# Cria a nova coluna de nomes da tecnologia\n",
    "patentes_df.drop(['tecnologia'], axis=1, inplace=True) # remove as colunas tecnologia antiga para criar de novo com o padrão 00X\n",
    "patentes_df['tecnologia'] = patentes_df['nr_tech'] + patentes_df['nome_tech'] # recria a coluna tecnologia com padrão 00X\n",
    "\n",
    "# Caso das tecnologias antigas e que não estão no SICI - Nome\n",
    "patentes_df['tecnologia'] = np.where(patentes_df['tecnologia'] == \"\", patentes_df['registro'], patentes_df['tecnologia']) # padrão de nome das tecnologias antigas\n",
    "patentes_df['nr_tech'] = np.where(patentes_df['nome_tech'].isnull(),\"\",patentes_df['nr_tech']) # if tech name is blank, make tech number blank too\n",
    "patentes_df['tecnologia'] = np.where(patentes_df.tecnologia.str.endswith(('_')) == True,patentes_df['registro'],patentes_df['tecnologia']) # if the value in tech column endswith \"_\", replace by the register number\n",
    "# Replace the nr_tech column with a empty space if is a old inova tech \n",
    "patentes_df.loc[patentes_df['nr_tech'].str.startswith(\"PI\"), 'nr_tech'] = \"\"\n",
    "patentes_df.loc[patentes_df['nr_tech'].str.startswith(\"BR\"), 'nr_tech'] = \"\"\n",
    "patentes_df.loc[patentes_df['nr_tech'].str.startswith(\"MU\"), 'nr_tech'] = \"\"\n",
    "patentes_df.loc[patentes_df['nr_tech'].str.startswith(\"CA\"), 'nr_tech'] = \"\"\n",
    "patentes_df.loc[patentes_df['nr_tech'].str.startswith(\"PCT\"), 'nr_tech'] = \"\"\n",
    "\n",
    "# Cria a coluna com o nome do arquivo para download e a pasta no padrão do SICI-Inova\n",
    "patentes_df['f_name'] = patentes_df['nr_tech'] + patentes_df['registro'] + \"_EXIGENCIA_\" + patentes_df['cod_despacho'] + \"_\" + patentes_df['data de publicação'].str[0:2] + patentes_df['data de publicação'].str[3:5] + patentes_df['data de publicação'].str[8:11]\n",
    "patentes_df['folder_name'] = \"PareceresRPI/\" + patentes_df['tecnologia'] + \"/\" + patentes_df['nr_tech'] + \"EXIGENCIAS/\" + \"E_PAT_RPI\" + patentes_df['rpi'].astype(str) + \"_\" + patentes_df['data de publicação'].str[0:2] + patentes_df['data de publicação'].str[3:5] + patentes_df['data de publicação'].str[8:11]\n",
    "patentes_df.drop(['nr_tech','nome_tech'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "DocdEmjtrKsL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title PARTE 5: FAZER O DOWNLOAD DOS PARECERES DA RPI\n",
    "\n",
    "column_names = ['inpi_name','rpi','cod_busca'] # cria as colunas do dataframe\n",
    "df_inpi = pd.DataFrame(columns=column_names) # cria o dataframe\n",
    "\n",
    "rpi = rpi_i\n",
    "for i in range(rpi_f-rpi_i+1):\n",
    "    url = 'https://parecer.inpi.gov.br/arquivos/RPI/' + str(rpi)\n",
    "    \n",
    "    # verifica se os arquivos já estão disponíveis no servidor\n",
    "    if requests.get(url, verify=False).status_code != 200:\n",
    "        print(\"Não existem arquivos no servidor para esta revista.\")\n",
    "        sys.exit()\n",
    "    \n",
    "    # Monta o dataframe do inpi\n",
    "    df_temp = pd.read_html(requests.get(url, verify=False).content, encoding='utf-8', header=0)[0].iloc[2:-1]\n",
    "    df_temp.drop(df_temp.columns.difference(['Name']), axis=1, inplace=True)\n",
    "    df_temp.columns = ['inpi_name'] # renomeia as colunas do inpi\n",
    "    df_temp.loc[:,'rpi'] = rpi\n",
    "    df_temp['cod_busca'] = df_temp['inpi_name'].str[3:-11] # cria a coluna com o código de busca\n",
    "    df_inpi = df_inpi.append(df_temp) \n",
    "    del df_temp\n",
    "    rpi+=1\n",
    "    \n",
    "df_inpi = df_inpi.reset_index(drop=True)\n",
    "\n",
    "patentes_df = pd.merge(patentes_df, df_inpi, left_on=['rpi','cod_busca'],right_on=['rpi','cod_busca'],how='left') # mescla os dataframe sici e inpi    \n",
    "patentes_df.drop(['cod_busca'], axis=1, inplace=True)\n",
    "download_parecer(patentes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "l9zQmsOkHOSI"
   },
   "outputs": [],
   "source": [
    "#@title PARTE 6: CRIAR O ARQUIVO ZIP\n",
    "\n",
    "# Para uso no Google Colab\n",
    "\n",
    "# download dos arquivos em zip\n",
    "if rpi_f > rpi_i:\n",
    "    zip_file = \"PareceresRPI_\" + str(rpi_i) + \"-\" + str(rpi_f) + \".zip\"\n",
    "    zip_folder = \"PareceresRPI\"\n",
    "if rpi_f <= rpi_i:\n",
    "    zip_file = \"PareceresRPI_\" + str(rpi_i) + \".zip\"\n",
    "    zip_folder = \"PareceresRPI\"\n",
    "\n",
    "# download dos arquivos em zip\n",
    "#zip_file = f_revista + \".zip\"\n",
    "#zip_folder = f_revista\n",
    "\n",
    "# !zip -r /content/file.zip /content/Folder_To_Zip\n",
    "!zip -r \"$zip_file\" \"$zip_folder\" *.xlsx\n",
    "\n",
    "print(\"Tudo terminado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "QfaBWdBpdcn8"
   },
   "outputs": [],
   "source": [
    "#@title PARTE 7: LIMPAR ARQUIVOS DA NUVEM\n",
    "!rm \"$arquivo\"\n",
    "!rm -rf \"$zip_folder\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "INOVA - Download de Pareceres de Patentes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
