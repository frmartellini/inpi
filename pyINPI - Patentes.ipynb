{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "109ljONzHOP_"
   },
   "outputs": [],
   "source": [
    "## Carrega as bibliotecas necessárias\n",
    "\n",
    "import requests # módulo para enviar requisições HTTP\n",
    "import os # módulo para usar funcionalidades do sistema operacional\n",
    "import pandas as pd # ferramentas de manipulação e análise de dados\n",
    "import numpy as np # pacote para computação científica\n",
    "import sys # para e funções específicas do sistema\n",
    "import zipfile # módulo para trabalhar com arquivos zip\n",
    "import io # ferramentas fundamentais para trabalhar com fluxos de dados\n",
    "from bs4 import BeautifulSoup # biblioteca para extrair informação de arquivos HTML ou XML\n",
    "import re # operações com expressões regulares\n",
    "from itertools import groupby # agrupa valores de uma lista de acordo com o valor de uma função chave\n",
    "\n",
    "if 'google.colab' in str(get_ipython()): # se o Google Colab estiver sendo usado, instala as bibliotecas necessárias\n",
    "    from google.colab import files # módulo para fazer upload de arquivos a partir de sistema de arquivos local\n",
    "    !pip install -q XlsxWriter # módulo para gerar e editar arquivos xlsx\n",
    "else:  # caso contrário substitui o filtro padrão de mensagens de erro\n",
    "    if not sys.warnoptions: # substitui o filtro padrão de mensagens de erro para ocultar os avisos de SSL\n",
    "        import warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Variável global para definir o uso o arquivo xml no lugar do arquivo txt: mudar para False se for fazer a busca\n",
    "# somente com nos arquivos txt que estão disponíveis para todas as RPIs\n",
    "# O xml é mais bem estruturado, o que pode reduzir os erros na extração, mas está disponível apenas a partir da\n",
    "# RPI 2574, e a busca dentro dele é mais lenta\n",
    "flag_xml = True\n",
    "        \n",
    "# A 2531 não encontrar o xml diretamente corrigir no código - CORRIGIDO MAS TESTAR\n",
    "# Até a 2573 existe somente o arquivo TXT e não o xml - INCLUIR NA DOCUMENTAÇÂO\n",
    "# O txt existe a partir da 1132 - INCLUIR NA DOCUMENTAÇÃO\n",
    "# até a 1415 o ano da data de publicação tem dois digitos DD/MM/AA e não DD/MM/AAAA - CORRIGIDO MAS TESTAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas carregadas.\n"
     ]
    }
   ],
   "source": [
    "## Funções e classes para obter, fazer o download e gerar relatórios para a Revista de Propriedade Intelectual (RPI)\n",
    "\n",
    "class api_inpi: # Classe para acessar e extrair informações patentárias da API do INPI\n",
    "    \n",
    "    def __init__(self, url): # construtor para inicializar as propriedades da classe\n",
    "        self.url = url\n",
    "    \n",
    "    def arquivo_rpi(self,rpi): # verifica o status da RPI e extrai o arquivo xlm ou txt do pacote zip\n",
    "        global flag_xml\n",
    "        r = requests.head(self.url) # faz uma HEAD request e retorna o HTTP header com o código de status\n",
    "        \n",
    "        if r.status_code == 200: # se o código retornado for 200 procede com o download\n",
    "            r = requests.get(url, stream=True) # solicita os dados do servidor\n",
    "            file_zip = zipfile.ZipFile(io.BytesIO(r.content)) # faz o download do ZIP e extrai o conteúdo na memória\n",
    "            f_names = file_zip.namelist() # lista o nome dos arquivos do arquivo ZIP da RPI\n",
    "            \n",
    "            for fileName in f_names: # para cada arquivo dentro lista de nomes\n",
    "                if rpi < 2574 or flag_xml == False: # Até a RPI 2573, extraí o arquivo txt\n",
    "                    if fileName.endswith('.txt') or fileName.endswith('.TXT'): # seleciona o arquivo txt\n",
    "                        file_zip.extract(fileName) # extrai do pacote zip\n",
    "                        unziped_file = fileName # e armazena o nome em uma variável\n",
    "                if rpi >= 2574 and flag_xml == True: # A partir da RPI 2574, extraí o arquivo xml\n",
    "                    if fileName.endswith('.xml') or fileName.endswith('.XML'): # seleciona o arquivo xml\n",
    "                        file_zip.extract(fileName) # extrai do pacote zip\n",
    "                        unziped_file = fileName # e armazena o nome em uma variável\n",
    "                    \n",
    "            return unziped_file # retorna o nome do arquivo\n",
    "        \n",
    "        if r.status_code == 302: # se o código for 302, o arquivo ainda não está disponível\n",
    "            print(\"O Arquivo da RPI ainda não está disponível, tente mais tarde.\")\n",
    "            \n",
    "    # Procura os pareceres de patentes pelo nome do titular\n",
    "    def busca_titular(self,rpi,org,df):\n",
    "        global flag_xml\n",
    "        f_rpi = self.arquivo_rpi(rpi) # obtêm o arquivo xml da rpi\n",
    "        \n",
    "        if rpi < 2574 or flag_xml == False: # Até a RPI 2573 ou parse o TXT\n",
    "            with open(f_rpi, 'rt', encoding = \"ISO-8859-1\") as f: # abre o arquivo e codifica em ISO-8859-1\n",
    "                file_data = f.readlines() # armazena o conteúdo do arquivo em uma variável\n",
    "            \n",
    "            file_data = [re.sub(r' +', ' ', i) for i in file_data] # remove os espaços em branco contínuos do documento\n",
    "            file_data = [re.sub(r' $', '', i) for i in file_data] # remove o espaço em branco no final do elemento da  lista, se houver\n",
    "            file_data = [re.sub(r' \\n', '', i) for i in file_data] # remove ocorrências de \\n dentro dos elementos da lista\n",
    "            file_data = [re.sub(r'\\|\\n', '', i) for i in file_data] # remove ocorrências de \\n dentro dos elementos da lista\n",
    "            file_data = [re.sub(r'\\n', '', i) for i in file_data] # remove ocorrências de \\n dentro dos elementos da lista\n",
    "            \n",
    "            file_data = [re.sub(r'(?i)\\(cd\\) ', '(cd)', i) for i in file_data] # normaliza o marcador de código do serviço em lower case\n",
    "            file_data = [re.sub(r'(?i)\\(co\\) ', '(co)', i) for i in file_data] # normaliza o marcador de comentário em lower case\n",
    "            \n",
    "            if rpi <= 1415: # neste caso, o ano da publicação tem o formato DD/MM/AA\n",
    "                data_revista = str(file_data[0][-8:-3]) + \"/19\" + str(file_data[0][-2:]) # incluí o número 19 na frente do ano          \n",
    "            if rpi > 1415:  # neste caso, o ano da publicação tem o formato DD/MM/AAAA\n",
    "                data_revista = file_data[0][-10:] # extrai da data de publicação da RPI\n",
    "            \n",
    "            # separa o inid do código de despacho, delimitando os subgrupos do arquivo\n",
    "            grouped_data = []\n",
    "            for i in file_data:\n",
    "                grouped_data+=i.split(\"(cd)\")\n",
    "            \n",
    "            del file_data # apaga a variável temporária com os dados do arquivo da rpi\n",
    "            \n",
    "            # Divide a listagem da RPI em subgrupos a partir da marca deixada pelo código de despacho\n",
    "            grouped_data = [list(j) for i, j in groupby(grouped_data, lambda x:x == \"\") if not i]\n",
    "            \n",
    "            # Busca pela organização\n",
    "            match = []\n",
    "            for x, content_line in enumerate(grouped_data): # faz a busca nas listas de patentes\n",
    "                for y, content_column in enumerate(content_line): # faz a busca dentro de cada lista de despachos\n",
    "                    if org.lower() in content_column.lower():\n",
    "                        for w, reg in enumerate(grouped_data[x]): # faz a busca novamente na lista de patentes\n",
    "                            if \"(11) \" in reg: # mas buscando o número da patente\n",
    "                                match.append(reg[5:]) # para incluir em uma lista de índices\n",
    "                            if \"(11) \" not in reg: # caso não encontre o INID 11, número da patente\n",
    "                                if \"(21) \" in reg: # busca pelo INID 21, número do pedido\n",
    "                                    match.append(reg[5:]) # para incluir em uma lista de índices\n",
    "                                    \n",
    "            # Busca pela ocorrência do número de patentes na lista de índices\n",
    "            for z, reg in enumerate(match): # navega pela lista de índices\n",
    "                for x, content_line in enumerate(grouped_data): # faz a busca nas listas de patentes\n",
    "                    for y, content_column in enumerate(content_line): # faz a busca dentro de cada lista de despachos\n",
    "                        if match[z] in content_column: # se a proteção está dentro da lista de despachos\n",
    "                            for w, data_dep in enumerate(grouped_data[x]): # faz a busca novamente na lista de patentes \n",
    "                                if \"(22) \" in data_dep: # buscando pela data de depósito\n",
    "                                    data_deposito = data_dep[5:]                                    \n",
    "                                    df.loc[len(df)] = [rpi,data_revista,reg,data_deposito]\n",
    "                                    \n",
    "        if rpi >= 2574 and flag_xml == True: # Faz a busca no arquivo xml, disponível a partir da RPI 2574\n",
    "            infile = open(f_rpi,'r') # abre o arquivo da rpi\n",
    "            file_data = infile.read() # armazena o conteúdo do arquivo em uma variável\n",
    "            file_data = re.sub(' +',' ',file_data) # substitui espaços múltiplos por espaçamentos simples\n",
    "            soup = BeautifulSoup(file_data, 'xml') # passa os dados armazenados para o analisador do beautifulsoup\n",
    "            \n",
    "            data_revista = soup.find('revista').attrs.get('dataPublicacao') # extrai a data de publicação\n",
    "        \n",
    "            # procura todas as ocorrências do nome do titular parece no arquivo xml\n",
    "            org_soup = soup.find_all('nome-completo', text=lambda x: x is not None and org in x.casefold())\n",
    "            despacho_len = len(org_soup) # conta o número de registros encontrados\n",
    "                \n",
    "            for i in range(despacho_len): # busca no arquivo xml para extrair as informações onde o titular foi encontrado\n",
    "                despacho_soup = org_soup[i].find_parent('despacho') # para o i-th elemento, encontra a tag pai <despacho>\n",
    "            \n",
    "                # para o i-th elemento, busca quantas vezes o número da proteção foi encontrado\n",
    "                registro_soup = soup.find_all('numero', text=lambda x: despacho_soup.find('numero').text in x)\n",
    "            \n",
    "                registro_len = len(registro_soup) # conta quantas vezes o número da proteção foi repetido\n",
    "            \n",
    "                # busca as informações para todas as vezes em que o número da proteção foi repetido\n",
    "                for j in range(registro_len):\n",
    "                    registros = registro_soup[j].find_parent('despacho')\n",
    "                \n",
    "                    registro = registros.find('numero') # busca pelo número da proteção\n",
    "                    if registro != None:\n",
    "                        registro = registro.text\n",
    "                    \n",
    "                    # define os códigos de busca padronizados, para fazer a busca no servidor web.\n",
    "                    # se o número de proteção começar com BR, remove BR, os espaços, o digito identificador e o hífen\n",
    "                    # para outras proteções, remove apenas o digito identificador e o hífen\n",
    "                    cod_busca = registro[:-2].replace(' ', '').replace('BR', '')\n",
    "        \n",
    "                    cod_despacho = registros.find('codigo') # busca pelo código de despacho\n",
    "                    if cod_despacho != None:\n",
    "                        cod_despacho = cod_despacho.text\n",
    "                    \n",
    "                    titulo = registros.find('titulo', inid=\"54\") # busca pelo título da patente\n",
    "                    if titulo != None:\n",
    "                        titulo = titulo.text\n",
    "                                \n",
    "                    kindcode = registros.find('numero').attrs.get('kindcode') # busca pelo kind code\n",
    "                    \n",
    "                    data_deposito = registros.find('data-deposito') # busca pela data de depósito\n",
    "                    if data_deposito != None:\n",
    "                        data_deposito = data_deposito.text\n",
    "                \n",
    "                    # busca pelas informações de classificação internacional \n",
    "                    ci_len = len(registros.find_all('classificacao-internacional'))\n",
    "                    ci = \"\"\n",
    "                    if ci_len > 0:\n",
    "                        for k in range(ci_len): # para o k-th elemento\n",
    "                            # armazena as informações de classificação internacional no formato\n",
    "                            # código de classificação internacional (ano) | ...\n",
    "                            ci_ano = registros.find_all('classificacao-internacional')[k].text + \" (\" + registros.find_all('classificacao-internacional')[k].attrs.get('ano') + \")\"\n",
    "                            ci = ci + ci_ano + \" | \"\n",
    "                    ci = ci[:-3]\n",
    "                \n",
    "                    # busca pelas informações de titularidade \n",
    "                    titulares_len = len(registros.find_all('titular'))\n",
    "                    titulares = \"\"\n",
    "                    gestao = \"Sim\"\n",
    "                    if titulares_len > 0:\n",
    "                        for k in range(titulares_len): # para o k-th elemento\n",
    "                            titular = registros.find_all('titular')[k].find('nome-completo').text\n",
    "                            if k == 0: # verifica o responsável pelo depósito da patente\n",
    "                                # se o primeiro titular não for a organização procurada,\n",
    "                                # define a variável gestão como Não\n",
    "                                if org.lower() not in titular.lower():\n",
    "                                    gestao = \"Não\"                            \n",
    "                            # armazena as informações de titularidade no formato\n",
    "                            # titular 1 | titular 2 | ...\n",
    "                            titulares = titulares + titular + \" | \"\n",
    "                    titulares = titulares[:-3]\n",
    "                \n",
    "                    # busca pelo nome dos inventores    \n",
    "                    inventor_len = len(registros.find_all('inventor'))\n",
    "                    inventores = \"\"\n",
    "                    if inventor_len > 0:\n",
    "                        for k in range(inventor_len): # para o k-th elemento\n",
    "                            # armazena o nome dos inventores no formato\n",
    "                            # inventor 1 | inventor 2 | ...\n",
    "                            inventor = registros.find_all('inventor')[k].find('nome-completo').text\n",
    "                            inventores = inventores + inventor + \" | \"\n",
    "                    inventores = inventores[:-3]\n",
    "                \n",
    "                    # armazena a informação extraída na i-th linha do dataframe\n",
    "                    df.loc[len(df)] = [rpi, data_revista,registro, kindcode, cod_despacho,titulo,gestao, titulares, inventores, data_deposito, ci,cod_busca]\n",
    "        \n",
    "            # define a coluna rpi do dataframe como tipo inteiro para evitar conflitos\n",
    "            df['rpi'] = df['rpi'].astype('int')\n",
    "            \n",
    "            # SÓ HABILITAR DEPOIS QUE IMPLEMENTAR PARA O TXT\n",
    "            # define a cluna cod_busca como tipo string para evitar conflitos\n",
    "            #df['cod_busca'] = df['cod_busca'].astype('str')\n",
    "            \n",
    "            # SÓ HABILITAR DEPOIS QUE IMPLEMENTAR PARA O TXT\n",
    "            # define a cluna cod_despacho como tipo string para evitar conflitos\n",
    "            #df['cod_despacho'] = df['cod_despacho'].astype('str')\n",
    "        \n",
    "        os.remove(f_rpi) # apaga o arquivo da rpi\n",
    "\n",
    "# Generate a report in xlsx format with the information parsed from the RPI\n",
    "#     Use: excel_report(source dataframe,file name,inside file sheet name)\n",
    "def excel_report(xls_df,xls_name,sheet_name):\n",
    "    writer = pd.ExcelWriter(xls_name + \".xlsx\", engine='xlsxwriter', date_format='dd/mm/yyyy') # create a pandas excel writer using XlsxWriter\n",
    "    xls_df.to_excel(writer, sheet_name=sheet_name, index=False) # convert the dataframe to an XlsxWriter Excel object\n",
    "    workbook  = writer.book # get the xlsxwriter workbook object\n",
    "    worksheet = writer.sheets[sheet_name] # get the xlsxwriter worksheet object\n",
    "    \n",
    "    for i, col in enumerate(xls_df.columns): # iterate through each column and set the width to the max length\n",
    "        column_len = xls_df[col].astype(str).str.len().max() # find length of column i\n",
    "        column_len = max(column_len, len(col)) + 2 # setting the length if the column header is larger than the max column value length\n",
    "        worksheet.set_column(i, i, column_len) # set the column length\n",
    "        \n",
    "    writer.save() # close the Pandas Excel writer and output the Excel file\n",
    "    print(\"RPI Report concluded!\")\n",
    "\n",
    "print(\"Bibliotecas carregadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite o número da primeira RPI:\n",
      "1132\n",
      "Digite o número da última RPI:\n",
      "(Caso seja somente uma edição, aperte ENTER)\n",
      "1416\n"
     ]
    }
   ],
   "source": [
    "## RPI selection\n",
    "\n",
    "rpi_i =  input(\"Digite o número da primeira RPI:\\n\")\n",
    "rpi_i = int(rpi_i)\n",
    "rpi_f =  input(\"Digite o número da última RPI:\\n(Caso seja somente uma edição, aperte ENTER)\\n\") or rpi_i\n",
    "rpi_f = int(rpi_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPI 1132 concluída.\n",
      "RPI 1133 concluída.\n",
      "RPI 1134 concluída.\n",
      "RPI 1135 concluída.\n",
      "RPI 1136 concluída.\n",
      "RPI 1137 concluída.\n",
      "RPI 1138 concluída.\n",
      "RPI 1139 concluída.\n",
      "RPI 1140 concluída.\n",
      "RPI 1141 concluída.\n",
      "RPI 1142 concluída.\n",
      "RPI 1143 concluída.\n",
      "RPI 1144 concluída.\n",
      "RPI 1145 concluída.\n",
      "RPI 1146 concluída.\n",
      "RPI 1147 concluída.\n",
      "RPI 1148 concluída.\n",
      "RPI 1149 concluída.\n",
      "RPI 1150 concluída.\n",
      "RPI 1151 concluída.\n",
      "RPI 1152 concluída.\n",
      "RPI 1153 concluída.\n",
      "RPI 1154 concluída.\n",
      "RPI 1155 concluída.\n",
      "RPI 1156 concluída.\n",
      "RPI 1157 concluída.\n",
      "RPI 1158 concluída.\n",
      "RPI 1159 concluída.\n",
      "RPI 1160 concluída.\n",
      "RPI 1161 concluída.\n",
      "RPI 1162 concluída.\n",
      "RPI 1163 concluída.\n",
      "RPI 1164 concluída.\n",
      "RPI 1165 concluída.\n",
      "RPI 1166 concluída.\n",
      "RPI 1167 concluída.\n",
      "RPI 1168 concluída.\n",
      "RPI 1169 concluída.\n",
      "RPI 1170 concluída.\n",
      "RPI 1171 concluída.\n",
      "RPI 1172 concluída.\n",
      "RPI 1173 concluída.\n",
      "RPI 1174 concluída.\n",
      "RPI 1175 concluída.\n",
      "RPI 1176 concluída.\n",
      "RPI 1177 concluída.\n",
      "RPI 1178 concluída.\n",
      "RPI 1179 concluída.\n",
      "RPI 1180 concluída.\n",
      "RPI 1181 concluída.\n",
      "RPI 1182 concluída.\n",
      "RPI 1183 concluída.\n",
      "RPI 1184 concluída.\n",
      "RPI 1185 concluída.\n",
      "RPI 1186 concluída.\n",
      "RPI 1187 concluída.\n",
      "RPI 1188 concluída.\n",
      "RPI 1189 concluída.\n",
      "RPI 1190 concluída.\n",
      "RPI 1191 concluída.\n",
      "RPI 1192 concluída.\n",
      "RPI 1193 concluída.\n",
      "RPI 1194 concluída.\n",
      "RPI 1195 concluída.\n",
      "RPI 1196 concluída.\n",
      "RPI 1197 concluída.\n",
      "RPI 1198 concluída.\n",
      "RPI 1199 concluída.\n",
      "RPI 1200 concluída.\n",
      "RPI 1201 concluída.\n",
      "RPI 1202 concluída.\n",
      "RPI 1203 concluída.\n",
      "RPI 1204 concluída.\n",
      "RPI 1205 concluída.\n",
      "RPI 1206 concluída.\n",
      "RPI 1207 concluída.\n",
      "RPI 1208 concluída.\n",
      "RPI 1209 concluída.\n",
      "RPI 1210 concluída.\n",
      "RPI 1211 concluída.\n",
      "RPI 1212 concluída.\n",
      "RPI 1213 concluída.\n",
      "RPI 1214 concluída.\n",
      "RPI 1215 concluída.\n",
      "RPI 1216 concluída.\n",
      "RPI 1217 concluída.\n",
      "RPI 1218 concluída.\n",
      "RPI 1219 concluída.\n",
      "RPI 1220 concluída.\n",
      "RPI 1221 concluída.\n",
      "RPI 1222 concluída.\n",
      "RPI 1223 concluída.\n",
      "RPI 1224 concluída.\n",
      "RPI 1225 concluída.\n",
      "RPI 1226 concluída.\n",
      "RPI 1227 concluída.\n",
      "RPI 1228 concluída.\n",
      "RPI 1229 concluída.\n",
      "RPI 1230 concluída.\n",
      "RPI 1231 concluída.\n",
      "RPI 1232 concluída.\n",
      "RPI 1233 concluída.\n",
      "RPI 1234 concluída.\n",
      "RPI 1235 concluída.\n",
      "RPI 1236 concluída.\n",
      "RPI 1237 concluída.\n",
      "RPI 1238 concluída.\n",
      "RPI 1239 concluída.\n",
      "RPI 1240 concluída.\n",
      "RPI 1241 concluída.\n",
      "RPI 1242 concluída.\n",
      "RPI 1243 concluída.\n",
      "RPI 1244 concluída.\n",
      "RPI 1245 concluída.\n",
      "RPI 1246 concluída.\n",
      "RPI 1247 concluída.\n",
      "RPI 1248 concluída.\n",
      "RPI 1249 concluída.\n",
      "RPI 1250 concluída.\n",
      "RPI 1251 concluída.\n",
      "RPI 1252 concluída.\n",
      "RPI 1253 concluída.\n",
      "RPI 1254 concluída.\n",
      "RPI 1255 concluída.\n",
      "RPI 1256 concluída.\n",
      "RPI 1257 concluída.\n",
      "RPI 1258 concluída.\n",
      "RPI 1259 concluída.\n",
      "RPI 1260 concluída.\n",
      "RPI 1261 concluída.\n",
      "RPI 1262 concluída.\n",
      "RPI 1263 concluída.\n",
      "RPI 1264 concluída.\n",
      "RPI 1265 concluída.\n",
      "RPI 1266 concluída.\n",
      "RPI 1267 concluída.\n",
      "RPI 1268 concluída.\n",
      "RPI 1269 concluída.\n",
      "RPI 1270 concluída.\n",
      "RPI 1271 concluída.\n",
      "RPI 1272 concluída.\n",
      "RPI 1273 concluída.\n",
      "RPI 1274 concluída.\n",
      "RPI 1275 concluída.\n",
      "RPI 1276 concluída.\n",
      "RPI 1277 concluída.\n",
      "RPI 1278 concluída.\n",
      "RPI 1279 concluída.\n",
      "RPI 1280 concluída.\n",
      "RPI 1281 concluída.\n",
      "RPI 1282 concluída.\n",
      "RPI 1283 concluída.\n",
      "RPI 1284 concluída.\n",
      "RPI 1285 concluída.\n",
      "RPI 1286 concluída.\n",
      "RPI 1287 concluída.\n",
      "RPI 1288 concluída.\n",
      "RPI 1289 concluída.\n",
      "RPI 1290 concluída.\n",
      "RPI 1291 concluída.\n",
      "RPI 1292 concluída.\n",
      "RPI 1293 concluída.\n",
      "RPI 1294 concluída.\n",
      "RPI 1295 concluída.\n",
      "RPI 1296 concluída.\n",
      "RPI 1297 concluída.\n",
      "RPI 1298 concluída.\n",
      "RPI 1299 concluída.\n",
      "RPI 1300 concluída.\n",
      "RPI 1301 concluída.\n",
      "RPI 1302 concluída.\n",
      "RPI 1303 concluída.\n",
      "RPI 1304 concluída.\n",
      "RPI 1305 concluída.\n",
      "RPI 1306 concluída.\n",
      "RPI 1307 concluída.\n",
      "RPI 1308 concluída.\n",
      "RPI 1309 concluída.\n",
      "RPI 1310 concluída.\n",
      "RPI 1311 concluída.\n",
      "RPI 1312 concluída.\n",
      "RPI 1313 concluída.\n",
      "RPI 1314 concluída.\n",
      "RPI 1315 concluída.\n",
      "RPI 1316 concluída.\n",
      "RPI 1317 concluída.\n",
      "RPI 1318 concluída.\n",
      "RPI 1319 concluída.\n",
      "RPI 1320 concluída.\n",
      "RPI 1321 concluída.\n",
      "RPI 1322 concluída.\n",
      "RPI 1323 concluída.\n",
      "RPI 1324 concluída.\n",
      "RPI 1325 concluída.\n",
      "RPI 1326 concluída.\n",
      "RPI 1327 concluída.\n",
      "RPI 1328 concluída.\n",
      "RPI 1329 concluída.\n",
      "RPI 1330 concluída.\n",
      "RPI 1331 concluída.\n",
      "RPI 1332 concluída.\n",
      "RPI 1333 concluída.\n",
      "RPI 1334 concluída.\n",
      "RPI 1335 concluída.\n",
      "RPI 1336 concluída.\n",
      "RPI 1337 concluída.\n",
      "RPI 1338 concluída.\n",
      "RPI 1339 concluída.\n",
      "RPI 1340 concluída.\n",
      "RPI 1341 concluída.\n",
      "RPI 1342 concluída.\n",
      "RPI 1343 concluída.\n",
      "RPI 1344 concluída.\n",
      "RPI 1345 concluída.\n",
      "RPI 1346 concluída.\n",
      "RPI 1347 concluída.\n",
      "RPI 1348 concluída.\n",
      "RPI 1349 concluída.\n",
      "RPI 1350 concluída.\n",
      "RPI 1351 concluída.\n",
      "RPI 1352 concluída.\n",
      "RPI 1353 concluída.\n",
      "RPI 1354 concluída.\n",
      "RPI 1355 concluída.\n",
      "RPI 1356 concluída.\n",
      "RPI 1357 concluída.\n",
      "RPI 1358 concluída.\n",
      "RPI 1359 concluída.\n",
      "RPI 1360 concluída.\n",
      "RPI 1361 concluída.\n",
      "RPI 1362 concluída.\n",
      "RPI 1363 concluída.\n",
      "RPI 1364 concluída.\n",
      "RPI 1365 concluída.\n",
      "RPI 1366 concluída.\n",
      "RPI 1367 concluída.\n",
      "RPI 1368 concluída.\n",
      "RPI 1369 concluída.\n",
      "RPI 1370 concluída.\n",
      "RPI 1371 concluída.\n",
      "RPI 1372 concluída.\n",
      "RPI 1373 concluída.\n",
      "RPI 1374 concluída.\n",
      "RPI 1375 concluída.\n",
      "RPI 1376 concluída.\n",
      "RPI 1377 concluída.\n",
      "RPI 1378 concluída.\n",
      "RPI 1379 concluída.\n",
      "RPI 1380 concluída.\n",
      "RPI 1381 concluída.\n",
      "RPI 1382 concluída.\n",
      "RPI 1383 concluída.\n",
      "RPI 1384 concluída.\n",
      "RPI 1385 concluída.\n",
      "RPI 1386 concluída.\n",
      "RPI 1387 concluída.\n",
      "RPI 1388 concluída.\n",
      "RPI 1389 concluída.\n",
      "RPI 1390 concluída.\n",
      "RPI 1391 concluída.\n",
      "RPI 1392 concluída.\n",
      "RPI 1393 concluída.\n",
      "RPI 1394 concluída.\n",
      "RPI 1395 concluída.\n",
      "RPI 1396 concluída.\n",
      "RPI 1397 concluída.\n",
      "RPI 1398 concluída.\n",
      "RPI 1399 concluída.\n",
      "RPI 1400 concluída.\n",
      "RPI 1401 concluída.\n",
      "RPI 1402 concluída.\n",
      "RPI 1403 concluída.\n",
      "RPI 1404 concluída.\n",
      "RPI 1405 concluída.\n",
      "RPI 1406 concluída.\n",
      "RPI 1407 concluída.\n",
      "RPI 1408 concluída.\n",
      "RPI 1409 concluída.\n",
      "RPI 1410 concluída.\n",
      "RPI 1411 concluída.\n",
      "RPI 1412 concluída.\n",
      "RPI 1413 concluída.\n",
      "RPI 1414 concluída.\n",
      "RPI 1415 concluída.\n",
      "RPI 1416 concluída.\n",
      "RPI Report concluded!\n"
     ]
    }
   ],
   "source": [
    "## Make the search in patent section of the RPI\n",
    "\n",
    "# Set the columns and create the dataframe to store information\n",
    "#column_names = ['rpi', 'data de publicação','registro','kind code','cod_despacho','título','gestão','titulares','inventores','data de deposito','classificação internacional','cod_busca'] # cria as colunas do dataframe\n",
    "#patentes_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# teste para o TXT, apagar depois que consolidar os dois tipos de arquivo\n",
    "column_names = ['rpi','data_rpi','registro','data_de_deposito'] # cria as colunas do dataframe\n",
    "patentes_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "rpi = rpi_i # set rpi counter as rpi_i\n",
    "for i in range(rpi_f-rpi_i+1): # for the i-th edition from the rpi\n",
    "    url = \"http://revistas.inpi.gov.br/txt/P\" + str(rpi) + \".zip\" # set the url to make the search\n",
    "    api_inpi(url).busca_titular(rpi,'universidade estadual de campinas',patentes_df) # make the search\n",
    "    print(\"RPI\", rpi, \"concluída.\")\n",
    "    rpi+=1 # ident the rpi counter\n",
    "\n",
    "if rpi_f > rpi_i: # if the last rpi is greather than firts\n",
    "    f_name = \"rpi_patentes_\" + str(rpi_i) + \"-\" + str(rpi_f) # set the xlsx filename\n",
    "    s_name = str(rpi_i) + \" - \" + str(rpi_f) # set the sheet filename\n",
    "if rpi_f <= rpi_i: # else \n",
    "    f_name = \"rpi_patentes_\" + str(rpi_i)  # set the xlsx filename\n",
    "    s_name = str(rpi_i)  # set the sheet filename\n",
    "\n",
    "excel_report(patentes_df,f_name,s_name) # generate the xlsx report with extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBA BR 11 2014 02740-6\n"
     ]
    }
   ],
   "source": [
    "patente = \"BR 11 2014 02740-6 CBA\"\n",
    "if len(patente) > 18:\n",
    "    kind_code = patente[-len(patente)+19:]\n",
    "    patente = patente[:-len(patente)+18]\n",
    "print(kind_code, patente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patente[:-len(patente)+18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the files from the web server\n",
    "\n",
    "# creates the columns with the file names and the folder names to download\n",
    "# in this example we use this pattern to folders, with three levels\n",
    "#     PareceresRPI/BR 10 2014 021620-0/RPI2589_180820\n",
    "# and this pattern to files\n",
    "#     PI 1104516-7_Despacho 7.1_180820_A.pdf\n",
    "patentes_df['f_name'] = patentes_df['registro'] + \"_Despacho \" + patentes_df['cod_despacho'] + \"_\" + patentes_df['data de publicação'].str[0:2] + patentes_df['data de publicação'].str[3:5] + patentes_df['data de publicação'].str[8:11]\n",
    "patentes_df['folder_name'] = \"PareceresRPI/\" + patentes_df['registro'] + \"/RPI\" + patentes_df['rpi'].astype(str) + \"_\" + patentes_df['data de publicação'].str[0:2] + patentes_df['data de publicação'].str[3:5] + patentes_df['data de publicação'].str[8:11]\n",
    "patentes_df.drop(patentes_df.columns.difference(['rpi','registro','cod_despacho','inpi_name','f_name','folder_name','cod_busca']), axis=1, inplace=True)\n",
    "\n",
    "# set te columns and create the dataframe to store information from INPI web server\n",
    "# for all selected editions\n",
    "column_names = ['inpi_name','rpi','cod_busca']\n",
    "df_inpi = pd.DataFrame(columns=column_names)\n",
    "\n",
    "rpi = rpi_i # set rpi counter as rpi_i\n",
    "for i in range(rpi_f-rpi_i+1): # for the i-th edition from the rpi\n",
    "    url = \"https://parecer.inpi.gov.br/arquivos/RPI/\" + str(rpi) # set the url to make the search\n",
    "    \n",
    "    if requests.get(url, verify=False).status_code != 200: # check if the files are avaiabel at web server\n",
    "        print(\"There are no files on the server for this edition.\")\n",
    "        sys.exit()\n",
    "    \n",
    "    # create a temporary dataframe to store the extract information from i-th edition\n",
    "    df_temp = pd.read_html(requests.get(url, verify=False).content, encoding='utf-8', header=0)[0].iloc[2:-1]\n",
    "    \n",
    "    df_temp.drop(df_temp.columns.difference(['Name']), axis=1, inplace=True) # drop all columns, except Name\n",
    "    df_temp.columns = ['inpi_name'] # rename the column\n",
    "    df_temp.loc[:,'rpi'] = rpi # create the columns with i-th RPI number for all records\n",
    "    df_temp['cod_busca'] = df_temp['inpi_name'].str[3:-11] # create the column with the search code\n",
    "    df_inpi = df_inpi.append(df_temp) # append the records for the i-th rpi at the end of INPI dataframe \n",
    "    del df_temp # delete temporary dataframe\n",
    "    rpi+=1 # ident the rpi number\n",
    "    \n",
    "df_inpi = df_inpi.reset_index(drop=True) # reset the index from rpi dataframe\n",
    "\n",
    "# merge the datframes with the information extracted from RPI and INPI web server\n",
    "patentes_df = pd.merge(patentes_df, df_inpi, left_on=['rpi','cod_busca'],right_on=['rpi','cod_busca'],how='left')    \n",
    "patentes_df.drop(['cod_busca'], axis=1, inplace=True) # after this, drop the column with the search code\n",
    "\n",
    "# remove the records that are not in both dataframes\n",
    "patentes_df.dropna(subset = ['registro'], inplace=True) # remove the lines where pi is NaN\n",
    "patentes_df.dropna(subset = ['inpi_name'], inplace=True) # remove the lines where inpi_name is NaN\n",
    "\n",
    "patentes_df['download'] = True # create a column and set dowload as True\n",
    "\n",
    "# cases where a protection has two orders in the same magazine\n",
    "# it is necessary to keep only the documents for one of the dispatch numbers\n",
    "# so set dowload as False\n",
    "patentes_df.loc[patentes_df.cod_despacho == '15.11', 'download'] = False # the documents are duplicated between 15.11 and 6.22\n",
    "patentes_df.loc[patentes_df.cod_despacho == '8.7', 'download'] = False # the documents are duplicated between 7.5 and 8.7\n",
    "# the patent certificate is not on the same server as the patent reports\n",
    "# and must be downloaded directly from the INPI website\n",
    "patentes_df.loc[patentes_df.cod_despacho == '16.1', 'download'] = False # set download as False\n",
    "patentes_df.loc[patentes_df['download'] == False,'download'] = np.nan # change False to NaN at download\n",
    "patentes_df.dropna(subset = ['download'], inplace=True) # remove the lines where download is NaN  \n",
    "patentes_df.drop(['download'], axis=1, inplace=True) # remove the download column\n",
    "\n",
    "# adding count flags to reports when there is more than one document\n",
    "patentes_df['dupl'] = patentes_df['registro'].duplicated(keep=False) # create dupl column\n",
    "patentes_df['flag'] = patentes_df.groupby('registro').cumcount() # group by register number and count\n",
    "patentes_df.loc[patentes_df['dupl'] == False, 'flag'] = \"\" # if there only one document, the flag column is empty\n",
    "# in this example, we changed the numeric counters to alphabetic counters using a dict\n",
    "dict_letters = {'' : '', 0 : '_A',1 : '_B', 2 : '_C', 3 : '_D', 4 : '_E', 5 : '_F', 6 : '_G', 7 : '_H', 8 : '_I', 9 : '_J'}\n",
    "patentes_df['flag']= patentes_df['flag'].map(dict_letters)  # change the counters\n",
    "patentes_df.drop(['dupl'], axis=1, inplace=True) # remove the column dupl\n",
    "patentes_df['f_name'] = patentes_df['f_name'] + patentes_df['flag'] + '.pdf' # add the count flags and pdf extension to filename\n",
    "patentes_df.drop(['flag'], axis=1, inplace=True) # remove the column flag\n",
    "\n",
    "i = 1 # start position in the dataframe to perform the download of the files\n",
    "# for the i-th elementh in the dataframe\n",
    "for folder_name,inpi_name,f_name,rpi in zip(patentes_df['folder_name'],patentes_df['inpi_name'],patentes_df['f_name'],patentes_df['rpi']):\n",
    "    if not os.path.exists(folder_name): # if the download folder not exist\n",
    "        os.makedirs(folder_name) # create the folder\n",
    "    url_cam = \"http://parecer.inpi.gov.br/download.php?cam=arquivos/RPI/\" + str(rpi) + \"/\" + inpi_name # set the url to download\n",
    "    f_request = requests.get(url_cam, verify = False)  # request data from the resource\n",
    "    path = folder_name + \"/\" + f_name # set the path to donwload the file\n",
    "    f = open(path, 'wb').write(f_request.content) # make the download\n",
    "    i+=1 # ident the position counter\n",
    "\n",
    "print(\"Download completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPI Report concluded!\n"
     ]
    }
   ],
   "source": [
    "file = \"datas_deposito1.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file)\n",
    "df = df.drop_duplicates(subset=['registro'])\n",
    "excel_report(df,\"datas_deposito\",\"datas_deposito\") # generate the xlsx report with extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['(cd)', '(cd)', '(cd)', '(DC) ']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = ['(Cd) ', '(cD) ','(CD) ','(DC) ']\n",
    "\n",
    "teste = [re.sub(r'(?i)\\(cd\\) ', '(cd)', file) for file in teste]\n",
    "\n",
    "print(type(teste))\n",
    "teste\n",
    "\n",
    "#data_revista = str(teste[-8:-3]) + \"/19\" + str(teste[-2:])\n",
    "#data_revista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_lst = ['cats1.fa', 'cats2.fa', 'dog1.fa', 'dog2.fa']\n",
    "file_lst_trimmed =[]\n",
    "\n",
    "file_lst_trimmed = [re.sub(r'\\d\\.fa$', '', file) for file in file_lst]\n",
    "type(file_lst_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pyINPI - Patentes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
